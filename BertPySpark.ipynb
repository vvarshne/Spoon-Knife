{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertPySpark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3wlNEBkvEtcczMPKKJ3jI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvarshne/Spoon-Knife/blob/master/BertPySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOJPW31zM4ic",
        "outputId": "59861e70-edba-4125-8e42-272478dd15d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "Processing /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471/pyspark-2.4.4-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.6\n",
            "Collecting spark-nlp\n",
            "  Using cached https://files.pythonhosted.org/packages/4e/b9/2fad4ac1c115dbd1487627e4a95458f9aa5a6a641798d5d10d1ce3eb61bd/spark_nlp-2.6.1-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izjLFqBRNhMp",
        "outputId": "e88d34a5-f9b7-4c13-8eab-26f73aae10f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import sparknlp \n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.6.1\n",
            "Apache Spark version:  2.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z2iw4n-NpE1",
        "outputId": "76957c19-a9ef-4af4-9dac-c6bfe118526d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YshWIkxNsSD"
      },
      "source": [
        "! mkdir -p data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_qdiBiNvYk",
        "outputId": "fd247844-756f-4eae-bf83-6224cdfd6354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('mini_newsgroups.tar.gz'):\n",
        "    ! wget https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/mini_newsgroups.tar.gz\n",
        "    ! tar xzf mini_newsgroups.tar.gz -C ./data/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-25 20:02:17--  https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/mini_newsgroups.tar.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1860687 (1.8M) [application/x-httpd-php]\n",
            "Saving to: ‘mini_newsgroups.tar.gz’\n",
            "\n",
            "mini_newsgroups.tar 100%[===================>]   1.77M  3.94MB/s    in 0.5s    \n",
            "\n",
            "2020-09-25 20:02:18 (3.94 MB/s) - ‘mini_newsgroups.tar.gz’ saved [1860687/1860687]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMD-lo45NyHj"
      },
      "source": [
        "from collections import defaultdict, Counter, OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sparse\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import brown\n",
        "en_stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRrrm7mgN0uc"
      },
      "source": [
        "def detokenize(sentence):\n",
        "    text = ''\n",
        "    for token in sentence:\n",
        "        if text and any(c.isalnum() for c in token):\n",
        "            text += ' '\n",
        "        text += token\n",
        "    return text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfE7vqdRN3Cj"
      },
      "source": [
        "def process(sentence):\n",
        "    terms = []\n",
        "    for term in sentence:\n",
        "        term = term.lower()\n",
        "        if term not in en_stopwords and term.isalnum():\n",
        "            terms.append(term)\n",
        "    return terms"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB-s5JXGN50T"
      },
      "source": [
        "\n",
        "docs = OrderedDict()\n",
        "\n",
        "for fid in brown.fileids():\n",
        "    docs[fid] = brown.sents(fid)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxLqMpqaOAix"
      },
      "source": [
        "ix2doc = list(docs)\n",
        "doc2ix = {fid: i for i, fid in enumerate(ix2doc)}\n",
        "vocabulary = set()\n",
        "\n",
        "term_counts = defaultdict(Counter)\n",
        "document_counts = Counter()\n",
        "\n",
        "for fid, doc in docs.items():\n",
        "    unique_terms = set()\n",
        "    for sentence in doc:\n",
        "        sentence = process(sentence)\n",
        "        term_counts[fid].update(sentence)\n",
        "        unique_terms.update(sentence)\n",
        "    document_counts.update(unique_terms)\n",
        "    vocabulary.update(unique_terms)\n",
        "\n",
        "ix2term = sorted(list(vocabulary))\n",
        "term2ix = OrderedDict()\n",
        "for i, term in enumerate(ix2term):\n",
        "    term2ix[term] = i"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8SqOUqA3gEM"
      },
      "source": [
        "term_count_mat = sparse.dok_matrix((len(doc2ix), len(term2ix)))\n",
        "\n",
        "for fid, i in doc2ix.items():\n",
        "    for term, count in term_counts[fid].items():\n",
        "        j = term2ix[term]\n",
        "        term_count_mat[i, j] = count\n",
        "term_count_mat = term_count_mat.todense()\n",
        "\n",
        "doc_count_vec = np.array(\n",
        "    [document_counts[term] for term in term2ix.keys()])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIz-vHrC3jPZ"
      },
      "source": [
        "tf = np.log(term_count_mat + 1)\n",
        "idf = len(doc2ix) / (1 + doc_count_vec)\n",
        "\n",
        "tfidf = np.multiply(tf, idf)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmpilj7d3lWi",
        "outputId": "22d73198-bf71-480d-d865-7724ca78b0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tfidf.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 40881)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}